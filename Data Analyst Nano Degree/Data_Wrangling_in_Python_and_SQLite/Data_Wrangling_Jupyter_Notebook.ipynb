{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Wrangling\n",
    "\n",
    "### Author: Carl (Andrew) Perkins\n",
    "\n",
    "### Date: April 9, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Area\n",
    "\n",
    "### Beechmont (Louisville), KY, U.S.A.\n",
    "\n",
    "The data used for this case study was pulled from Open Street Map using the Overpass API at the following link:\n",
    "<a href=\"https://www.openstreetmap.org/#map=5/51.500/-0.100\">Open Street Map</a>\n",
    "\n",
    "The data was originally imported as an OSM file, converted into CSV and finally pulled into SQLite.\n",
    "\n",
    "Beechmont is a municipality of the great Louisville Metro area in Kentucky. I currently live in Louisville, and I am interested to see what contributions are currently in the map and what can be known moving forward using a variety of query techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Problems in the Map\n",
    "\n",
    "#### First I looked at a 1% sample of the 151 MB dataset; I then used a variety of techniques as follows to identify problems in the larger set of data:\n",
    "\n",
    "#### 1.) First after reviewing some of the data, I used Python code to audit and clean the street addresses within the OSM file itself. Most of the dirty data was due to over abbreviated street names, phone numbers or lengths of the numbers themselves. The Python code used to audit and clean the addresses is located below. The code directly following the below code is the Python used to import into CSV files and clean the data just a bit more.\n",
    "\n",
    "\n",
    "#### 2.) After I converted the data into CSV and imported into SQLlite, I used the following queries to audit once more for a final pass at any inaccurate \"dirty\" data.\n",
    "\n",
    "##### Please note that the following Schema was used in the SQL Database:\n",
    "<a href=\"https://gist.github.com/swwelch/f1144229848b407e0a5d13fcb7fbbd6f\">Schema</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code used to audit and clean streed addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "from num2words import num2words\n",
    "\n",
    "OSMFILE = \"map.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "nth_re = re.compile(r'\\d\\d?(st|nd|rd|th|)', re.IGNORECASE)\n",
    "nesw_re = re.compile(r'\\s(North|East|South|West)$')\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Circle\", \"Crescent\", \"Gate\", \"Terrace\", \"Grove\", \"Way\"]\n",
    "\n",
    "mapping = { \n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"STREET\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Ehs\": \"EHS\",\n",
    "            \"Trl\": \"Trail\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Cir.\": \"Circle\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"Ct.\": \"Court\",\n",
    "            \"Crt\": \"Court\",\n",
    "            \"Crt.\": \"Court\",\n",
    "            \"By-pass\": \"Bypass\",\n",
    "            \"N.\": \"North\",\n",
    "            \"N\": \"North\",\n",
    "            \"E.\": \"East\",\n",
    "            \"E\": \"East\",\n",
    "            \"S.\": \"South\",\n",
    "            \"S\": \"South\",\n",
    "            \"W.\": \"West\",\n",
    "            \"W\": \"West\"\n",
    "          }\n",
    "\n",
    "street_mapping = {\n",
    "                   \"St\": \"Street\",\n",
    "                   \"St.\": \"Street\",\n",
    "                   \"ST\": \"Street\",\n",
    "                   \"STREET\": \"Street\",\n",
    "                   \"Ave\": \"Avenue\",\n",
    "                   \"Ave.\": \"Avenue\",\n",
    "                   \"Rd.\": \"Road\",\n",
    "                   \"Dr.\": \"Drive\",\n",
    "                   \"Dr\": \"Drive\",\n",
    "                   \"Rd\": \"Road\",\n",
    "                   \"Rd.\": \"Road\",\n",
    "                   \"Blvd\": \"Boulevard\",\n",
    "                   \"Blvd.\": \"Boulevard\",\n",
    "                   \"Ehs\": \"EHS\",\n",
    "                   \"Trl\": \"Trail\",\n",
    "                   \"Cir\": \"Circle\",\n",
    "                   \"Cir.\": \"Circle\",\n",
    "                   \"Ct\": \"Court\",\n",
    "                   \"Ct.\": \"Court\",\n",
    "                   \"Crt\": \"Court\",\n",
    "                   \"Crt.\": \"Court\",\n",
    "                   \"By-pass\": \"Bypass\"\n",
    "                }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit_street(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python code used to clean phone number and insert into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "\n",
    "\n",
    "OSM_PATH = \"map.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "PHONENUM = re.compile(r'\\+1\\s\\d{3}\\s\\d{3}\\s\\d{4}')\n",
    "POSTCODE = re.compile(r'[A-z]\\d[A-z]\\s?\\d[A-z]\\d')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "def update_phone_num(phone_num):\n",
    "    \"\"\"\n",
    "    Clean phone number for insertion into SQL database\n",
    "    \"\"\"\n",
    "    # Check for valid phone number format\n",
    "    m = PHONENUM.match(phone_num)\n",
    "    if m is None:\n",
    "        # Convert all dashes to spaces\n",
    "        if \"-\" in phone_num:\n",
    "            phone_num = re.sub(\"-\", \" \", phone_num)\n",
    "        # Remove all brackets\n",
    "        if \"(\" in phone_num or \")\" in phone_num:\n",
    "            phone_num = re.sub(\"[()]\", \"\", phone_num)\n",
    "        # Space out 10 straight numbers\n",
    "        if re.match(r'\\d{10}', phone_num) is not None:\n",
    "            phone_num = phone_num[:3] + \" \" + phone_num[3:6] + \" \" + phone_num[6:]\n",
    "        # Space out 11 straight numbers\n",
    "        elif re.match(r'\\d{11}', phone_num) is not None:\n",
    "            phone_num = phone_num[:1] + \" \" + phone_num[1:4] + \" \" + phone_num[4:7] + \" \" + phone_num[7:]\n",
    "        # Add full country code\n",
    "        if re.match(r'\\d{3}\\s\\d{3}\\s\\d{4}', phone_num) is not None:\n",
    "            phone_num = \"+1 \" + phone_num\n",
    "        # Ignore tag if no area code and local number (<10 digits)\n",
    "        elif sum(c.isdigit() for c in phone_num) < 10:\n",
    "            return None\n",
    "    return phone_num\n",
    "\n",
    "\n",
    "def load_new_tag(element, secondary, default_tag_type):\n",
    "    \"\"\"\n",
    "    Load a new tag dict to go into the list of dicts for way_tags, node_tags\n",
    "    \"\"\"\n",
    "    new = {}\n",
    "    new['id'] = element.attrib['id']\n",
    "    if \":\" not in secondary.attrib['k']:\n",
    "        new['key'] = secondary.attrib['k']\n",
    "        new['type'] = default_tag_type\n",
    "    else:\n",
    "        post_colon = secondary.attrib['k'].index(\":\") + 1\n",
    "        new['key'] = secondary.attrib['k'][post_colon:]\n",
    "        new['type'] = secondary.attrib['k'][:post_colon - 1]\n",
    "\n",
    "    return new\n",
    "def string_case(s):  # change string into titleCase except for UpperCase\n",
    "    if s.isupper():\n",
    "        return s\n",
    "    else:\n",
    "        return s.title()\n",
    "    \n",
    "# return the updated names\n",
    "def update_name(name, mapping):\n",
    "    name = name.split(' ')\n",
    "    for i in range(len(name)):\n",
    "        if name[i] in mapping:\n",
    "            name[i] = mapping[name[i]]\n",
    "            name[i] = string_case(name[i])\n",
    "        else:\n",
    "            name[i] = string_case(name[i])\n",
    "\n",
    "    name = ' '.join(name)\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in NODE_FIELDS:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "\n",
    "        for child in element:\n",
    "            node_tag = {}\n",
    "            if LOWER_COLON.match(child.attrib['k']):\n",
    "                node_tag['type'] = child.attrib['k'].split(':', 1)[0]\n",
    "                node_tag['key'] = child.attrib['k'].split(':', 1)[1]\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = update_name(child.attrib['v'],mapping)\n",
    "                tags.append(node_tag)\n",
    "            elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                continue\n",
    "            else:                \n",
    "                node_tag['key'] = child.attrib['k']\n",
    "                node_tag['type'] = 'regular'\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = update_name(child.attrib['v'],mapping)\n",
    "                tags.append(node_tag)\n",
    "\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in WAY_FIELDS:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "\n",
    "        position = 0\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "\n",
    "            if child.tag == 'tag':\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    way_tag['type'] = child.attrib['k'].split(':', 1)[0]\n",
    "                    way_tag['key'] = child.attrib['k'].split(':', 1)[1]\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = update_name(child.attrib['v'],mapping)\n",
    "                    tags.append(way_tag)\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = update_name(child.attrib['v'],mapping)\n",
    "                    tags.append(way_tag)\n",
    "\n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    "\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "            \n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL code used to audit data as a final pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, key, value, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(r\"Data_Wrangling_DB.db\")\n",
    "\n",
    "#This following code reads is looking for any postal codes that don't match a 5 length format -- the expected outcome should\n",
    "# be 0 rows returned.\n",
    "pd.read_sql_query(\"Select * from nodes_tags where [key] = 'postcode' and length(value) < 5;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above's expected outcome should be 0 rows.  Due to the formatting of the Zipcode we are now seeing that they are all true 5 length characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>367811539</td>\n",
       "      <td>county_name</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>gnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>367811877</td>\n",
       "      <td>county_name</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>gnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3418007532</td>\n",
       "      <td>county_name</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>gnis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3418007533</td>\n",
       "      <td>county_name</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>gnis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id          key      value  type\n",
       "0   367811539  county_name  Jefferson  gnis\n",
       "1   367811877  county_name  Jefferson  gnis\n",
       "2  3418007532  county_name  Jefferson  gnis\n",
       "3  3418007533  county_name  Jefferson  gnis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following code prints all County_names -- the expected outcome should be \"Jefferson\"\n",
    "pd.read_sql_query(\"Select * from nodes_tags where [key] = 'county_name';\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the county_names above are showing that they reside in Jefferson county, which is correct for the city of Louisville."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shively</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parkway Village</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audubon Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lynnview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Watterson Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Poplar Hills</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             value\n",
       "0          Shively\n",
       "1       Louisville\n",
       "2  Parkway Village\n",
       "3     Audubon Park\n",
       "4         Lynnview\n",
       "5   Watterson Park\n",
       "6     Poplar Hills"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following code should return values where the city is distinctly (Louisville, Shively, Parkway Village, Audubon Park, \n",
    "# Lynnview, Watterson Park or Poplar Hills)\n",
    "pd.read_sql_query(\"Select distinct [value] from nodes_tags where [key] = 'city';\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above shows the distinct municipalities that are associated to the area in which Beechmont is within Louisville, KY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reads any phone number where the length would include the country code or a space to exclude it\n",
    "pd.read_sql_query(\"Select distinct [value] from nodes_tags where [key] = 'phone' and length(value) > 12;\", conn)\n",
    "\n",
    "#Reads any phone number where the value doesn't include the dashes for easy readability.\n",
    "pd.read_sql_query(\"Select distinct [value] from nodes_tags where [key] = 'phone' and value not like '%-%';\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the phone number values of any phone numbers that are not normalized, most specifically any with a length more than 12 and those that don't have dashes in their value at all.\n",
    "\n",
    "In summation, most of the data is now cleansed or normalized to a standard across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts, Statistics and more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dixie Highway</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South 3Rd Street</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Southern Parkway</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taylor Boulevard</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Preston Highway</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South 2Nd Street</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Poplar Level Road</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manslick Road</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crums Lane</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South 6Th Street</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gardiner Lane</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Street Andrews Church Road</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Berry Boulevard</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Crittenden Drive</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>West Wheatmore Drive</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Farnsley Road</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>South 1St Street</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Southside Drive</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bermuda Lane</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7Th Street Road</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Belmar Drive</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>South 5Th Street</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Longfield Avenue</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Huntington Park Drive</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Douglas PARK</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Renwood Boulevard</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Quail Court</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Strawberry Lane</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Utah Avenue</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rockford Lane</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>I 264 East</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>Larkspur Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>Lotus Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Luckert Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Manning Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>Mason Dixon Lane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Melvin Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Memorial Gardens Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>Monarch Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>Oaklawn Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>Ole Brickyard Circle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>Orange Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Ordnance Station Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Pemaquid Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Preston Hwy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Radio Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>Ralph Avenue;Cane Run Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Recovery Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>Rice Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>Rose Drive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>Sanita Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Sioux Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>South Shelby Street</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>Sundew Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Thruston Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Timber Way</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>Toll Plaza Road</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Venhoff Avenue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Wathen Lane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Weber Lane</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value  count\n",
       "0                  Dixie Highway    797\n",
       "1               South 3Rd Street    730\n",
       "2               Southern Parkway    664\n",
       "3               Taylor Boulevard    648\n",
       "4                Preston Highway    600\n",
       "5               South 2Nd Street    438\n",
       "6              Poplar Level Road    414\n",
       "7                  Manslick Road    384\n",
       "8                     Crums Lane    346\n",
       "9               South 6Th Street    342\n",
       "10                 Gardiner Lane    326\n",
       "11    Street Andrews Church Road    320\n",
       "12               Berry Boulevard    300\n",
       "13              Crittenden Drive    300\n",
       "14          West Wheatmore Drive    298\n",
       "15                 Farnsley Road    291\n",
       "16              South 1St Street    290\n",
       "17               Southside Drive    287\n",
       "18                  Bermuda Lane    280\n",
       "19               7Th Street Road    271\n",
       "20                  Belmar Drive    263\n",
       "21              South 5Th Street    262\n",
       "22              Longfield Avenue    259\n",
       "23         Huntington Park Drive    245\n",
       "24                  Douglas PARK    241\n",
       "25             Renwood Boulevard    241\n",
       "26                   Quail Court    232\n",
       "27               Strawberry Lane    232\n",
       "28                   Utah Avenue    227\n",
       "29                 Rockford Lane    226\n",
       "...                          ...    ...\n",
       "1276                  I 264 East      1\n",
       "1277             Larkspur Avenue      1\n",
       "1278                Lotus Avenue      1\n",
       "1279              Luckert Avenue      1\n",
       "1280                Manning Road      1\n",
       "1281            Mason Dixon Lane      1\n",
       "1282                Melvin Drive      1\n",
       "1283      Memorial Gardens Drive      1\n",
       "1284               Monarch Drive      1\n",
       "1285               Oaklawn Drive      1\n",
       "1286        Ole Brickyard Circle      1\n",
       "1287                Orange Drive      1\n",
       "1288      Ordnance Station Drive      1\n",
       "1289               Pemaquid Road      1\n",
       "1290                 Preston Hwy      1\n",
       "1291                 Radio Drive      1\n",
       "1292  Ralph Avenue;Cane Run Road      1\n",
       "1293               Recovery Road      1\n",
       "1294                 Rice Avenue      1\n",
       "1295                  Rose Drive      1\n",
       "1296                 Sanita Road      1\n",
       "1297                Sioux Avenue      1\n",
       "1298         South Shelby Street      1\n",
       "1299               Sundew Avenue      1\n",
       "1300             Thruston Avenue      1\n",
       "1301                  Timber Way      1\n",
       "1302             Toll Plaza Road      1\n",
       "1303              Venhoff Avenue      1\n",
       "1304                 Wathen Lane      1\n",
       "1305                  Weber Lane      1\n",
       "\n",
       "[1306 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This query is looking to see which street has the most hits for address data\n",
    "pd.read_sql_query(\"SELECT t.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION SELECT * FROM ways_tags) t WHERE t.key = 'street' GROUP BY t.value ORDER BY count DESC;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, Dixie Highway comes in number one for the most address hits. Dixie Highway is highly commercialized and has lots of businesses, as well as several homes that are located more outside of the city.\n",
    "\n",
    "#### Next let's look at our file sizes and differing counts of specific tables:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "File Sizes:\n",
    "\n",
    "    Map.osm .............. 151 MB\n",
    "    Sample.db ............. 15 MB\n",
    "    nodes.csv ............. 59 MB\n",
    "    nodes_tags.csv ........ 3 MB\n",
    "    ways.csv .............. 5 MB\n",
    "    ways_tags.csv ......... 11 MB\n",
    "    ways_nodes.cv ......... 17 MB  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0    620676"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(*) FROM nodes;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(*)\n",
       "0     79049"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(*) FROM ways;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of unique users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT(DISTINCT(users.uid))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COUNT(DISTINCT(users.uid))\n",
       "0                         252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(DISTINCT(users.uid)) FROM (SELECT uid FROM nodes UNION SELECT uid FROM ways) users;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Louisville is a \"foody\" town. The following is a listing of the most popular restaurants in the area:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value, num]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"SELECT t.value, COUNT(*) as num FROM nodes_tags t INNER JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i ON t.id=i.id WHERE t.key='cuisine' GROUP BY t.value ORDER BY num DESC;\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the null values I would say that this data needs more \"amenity\" data across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion I was able to clean most of the data and make sure that the data is normalized across the board.  Due to lack of information that I found when researching, I believe that the greatest room for improvement lies within increased data contributions.  Sunergos Coffee, for instance, is down the street and is not in the data. This is a coffee business that has been around for more than a decade, has won multiple national competitions, and is no where to be seen in this data. I would love to see increased data from more contributors down the road."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
